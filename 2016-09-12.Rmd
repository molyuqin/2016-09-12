---
title: "STA257"
author: "Neil Montgomery | HTML is official | PDF versions good for in-class use only"
date: "Last edited: `r format(Sys.time(), '%Y-%m-%d %H:%M')`"
output: 
  ioslides_presentation: 
    css: '../styles.css' 
    widescreen: true 
    transition: 0.001
---

# admin

## contact, websites, notes

|
--|--
date format | ISO8601
instructor | Neil Montgomery
email | neilm@mie.utoronto.ca
office | BA8137
office hours | any time
website | portal (announcements, grades, etc.)
github | https://github.com/sta257-fall-2016 (lecture material, code, etc.)

&nbsp;

**Official lecture notes are HTML.**

PDFs will be uploaded before classes for people who like to annotate them during lecture on a PED. **But they will never be updated after class.**

## evaluation, book, tutorials

what | when | how much
-----|------|---------
midterm 1 | 2016-10-03 (OOPS!) during class time | 25%
midterm 2 | 2016-11-14 during class time | 25%
exam | TBA | 50%

&nbsp;

The book is *Mathematical Statistics and Data Analysis, 3rd Edition* by Rice (also used in STA261). 

I will suggest exercises from this book each week. 

Your TA will work through some of them in tutorial each week.

## other resources

Other (free, downloadable PDF through library) similar books:

* *Introduction to Probability with Statistical Applications* by Schay (similar level)
* *An Intermediate Course in Probability* by Gut (more advanced)
* *Introduction to probability models* by S. Ross (a bit more engineer-y)

Avoid books with titles like *Introduction to Probability and Statistics For \<Some Certain Specific Type of Student or Career\>*

A very nice (free PDF through library) book for those really interested in the mathematics of all this is: *Elementary Analysis* by K. Ross. (Subtitled "The Theory of Calculus".)

Wikipedia, youtube, stackexchange, google. Lots of good stuff. Lots of bad stuff. 

# meanings of probability

## no need to write this down

* Physical, long term relative frequency, "repeated experiments", "frequentist", "propensity"

* Evidential, subjective, "Bayesian", inductive

Visit Department of Philosophy for more information.

Whatever the interpretation, the mathematical rules are the same, based on axioms that define how probabilities can be assiged to events.

# axiomatic approach to probability

## elements and sets { .small }

We can think of an element $\omega$ belonging to a set $A$. We can think of sets $A$ and $B$ along with a universal set $S$. We have the following notions, and more:

* Membership $\omega \in A$

* Union "or" $A \cup B$; Intersection "and" $A \cap B$; works for infinitely many

* Complement $A^c = \{w \in S : w \not\in A\}$

* Empty set has no elements: $\emptyset$

* Disjointness: $A \cap B = \emptyset$ (notice: not a probability concept)

* Subset: $A \subseteq B$ (and "proper subset")

* Set difference: $A\backslash B = A\cap B^c$

## sample space { .small }

Probability starts with a sample space $S$, a collection with all possible outcomes of the random process. Often cumbersome and arbitrary; mainly used this week. Examples:

* Coin toss: $\{H, T\}$

* Picking a card: $\{A\spadesuit, A\heartsuit, A\diamondsuit, A\spadesuit\}$

* Toss two coins: $\{HH, HT, TH, TT\}$. Or possibly: $\{\{H,H\}, \{H, T\}, \{T,T\}\}$

* A race among 8 horses: ?

* Toss a coin until a head appears: $\{H, TH, TTH, TTTH, \ldots\}$

* Pick a real number between 0 and 1 "uniformly": $(0, 1)$ (A "continuous" sample space.)

## event { .small }

An event is a collection of outcomes; equivalently a subset of the sample space S.

Naming conventions: Roman letter near the beginning $A,B,C,\ldots$ or $A_1,\ldots,A_n$ or $A_1, A_2, A_3,\ldots$ as required.

Many examples possible from the example sample spaces.

## it's really more complicated than that { .small }

This is an elementary course, so we will not concern ourselves with the fact that not *all* subsets of a sample space are allowed to be called "events".

Really an event has to be a "suitable" collection of outcomes. 

For finite and countable (i.e. "list-able") sample spaces, in fact *all* events are "suitable".

But not for uncountable sample spaces, such as $(0,1)$. 

The "space" of suitable events can be called $\mathcal{A}$. 

## the probability axioms

A *probability measure* is a real-valued function (usually called) $P$. Its domain is $\mathcal{A}$, a space of suitable events in $S$. In addition, it has the following properties:

1. $P(S) = 1$ 

2. $P(A) \ge 0$ for all *events* $A \in \mathcal{A}$. 

3. If $A_1, A_2, A_3,\ldots$ is a *disjoint* collection of events, then:

$$P\left(\bigcup_{i=1}^\infty A_i\right) = \sum_{i=1}^\infty P(A_i)$$

The last property is called "$\sigma-$additivity".

There is a notion of "probability triple" $(S, \mathcal{A}, P)$ when needed to be absolutly clear (which isn't often in this course.)

## the axiomatic approach

In the fussiest possible treatment, the first question is: are these axioms *consistent*, which is the same as asking "Are there any probability measures at all?"

Theorem 0: the axioms are consistent.

Proof: $\ldots$

Advanced note...when the sample space is something like $S=(0,1)$ and if we were to allow $\mathcal{A}$ to be the collection of *all* subsets of $S$, then the axioms are *inconsistent*.

Added after class due to interest from many students...the advanced note should be understood to include also the desire for the "uniform probability" on $S$ - in other words the probability to lie in $(a,b)$ with $0<a<b<1$ to be $b-a$. 

## everyday properties of $P$

Continuing with total and absolute fussiness:

Theorem 1: $P(\emptyset) = 0$

Proof: $\ldots$

Theorem 2: If $A_1$ and $A_2$ are disjoint then $P(A_1 \cup A_2) = P(A_1) + P(A_2)$.

Proof: $\ldots$ (Note added after class...from now on we don't need the "silly" infinite number of $\emptyset$ in any of the proofs.)

Theorem 2a: If $A_1,A_2,\ldots,A_n$ are disjoint then $P\left(\bigcup_{i=1}^n A_i\right) = \sum_{i=1}^n P(A_i)$ (called "finite additivity")

Proof: "Induction" (Note: the book lists this Theorem as an "axiom", which is not technically wrong but...)

## more everyday properties of $P$, with proofs

Theorem 3: $P(A^c) = 1 - P(A)$

Theorem 4: If $A \subseteq B$ then $P(A) \le P(B)$. "$P$ is monotone."

Theorem 4a: $P(B\backslash A) = P(B) - P(B \cap A)$ (*Proof left as exercise*)

Theorem 4b: If $A \subseteq B$ then $P(B\backslash A) = P(B) - P(A)$. (*Proof left as exercise. Note that any proof left as an exercise is always allowed to use theorems already proven, and anything from general maths and calculus.*)

Theorem 5: $P(A \cup B) = P(A) + P(B) - P(A \cap B)$ (and generalizations)

This is admittedly getting dull.
